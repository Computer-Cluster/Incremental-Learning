\section{Planeamiento}

Las Redes Neuronales Artificiales tienen la habilidad de poderse aprender una tarea, y poder hacer o resolver tareas de predicción o clasificiación básicamente. En este sentido, con algortimos de aprendizaje como el Backpropagation, pormite ajustar los pesos de una RNA para que esta pueda empezar a resolver una tarea particular.  No obstante, muchas de las tareas que se resuleven en la vida diara, van generando mas información con el tiempo, por ejemplo, el comportamiento de un una serie financiera, o bien la predicción del clima en una determinada región. Así,  se tiene el aprendizaje incremental, siendo un método poco explorado,  enfocado en poder aprender nueva informaicóndel problema, sin tener que volver a entrenar todo el modelo con la información anterior, y la nueva que acaba de lleger, i.e.  en los modelos actuales de aprendizaje máquina, si se usa un conjunto de datos para entrenar un modelo en especifico, dicho modelo es funcional para dicho conjunto de datos y la información que ello representa. Sin embargo, si es necesario incorporar nueva información al modelo, es necasario recolectar dicha informaicón nueva, agregarla a que se tenia anteriormente, y volver a entrenar todo el modelo para que este pueda incorporar la nueva información.

De esta forma, una red ya entrenada con un primer conjunto de datos $d_{1}$ se desea entrenar con un nuevo conjunto de datos del mismo problema $d_{2}$, al entrenar la red con $d_{2}$ se perderá en conocimeinto aprendido por $d_{1}$.  Si no se desea utilizar un modelo de aprendizaje incremental, se tendria que juntar el conjunto $d_{1}$ y $d_{2}$ en un solo conjunto y volver a entrenar la RAN para así poder incorporar el nuevo conocieinto ($d_{2}$) a la RNA. Si se desea utilizar el método de aprendizaje incremental, se puede entrenar en un primer moemnt a la red con el conjunto $d_{1}$, posteriormente con $d_{2}$ teniendo poca perdida de informaicón de $d_{1}$, Si más adelante llega mas información del provlema ($d_{3}$) que se desee incorporar a la base de conocimientos de la RNA, entonces solo habra que entrenar la RNA con $d_{3}$ usando el modelo incremental para tener una perdida minima de informción de $d_{1}$ y $d_{2}$. 

De esta forma, el presente trabajo tomara como base la investigación de \cite{Bullinaria2009}, en donde utiliza una configuración de pesos dobles (a una RNA se duplican todos sus pesos), donde a una capa de pesos duplicados se enlaza con una tasa de aprendizaje alta, para simular un rápido aprendizaje, y por ende simular lo que sería memoría a corto plazo. En su contraparte, la segunda capa de pesos duplicados, se enlaza con una tasa de aprendizaje baja para aprender lentmente un problema, simulado la memoria a largo plazo.  Es decir, al momento de aprender una tarea nueva,  una capa de pesos aprendera muy rápdio la nueva tarea (tasa alta de aprendizaje) y por ende olvidará más rápidamente los datos ya aprendizos anteriomente, por otro lado, la segunda capa de pesos duplicados, aprendera muy lentamente los nuevos datos que lleguan, y por ende olvidando poco la información que anteriormente se aprendio.  Considernado ello, y considernado también que la RNA trabaj en conjunto con ambas capas de pesos duplicados, se pondera la salida de la RNA para que pueda contemplar la información nueva que se acaba de agregar a la RNA, en ambas capas, así como la informacion que se acaba de olvidar de ambas capas de pesos.

El problema principal del aprendizaej incremental mostrado en \cite{Bullinaria2009}, es que entre más conjuntos de datos nuevos que lleguen,  mas se olvidaran los primeros conjuntos que se aprendieron, lo cual no es tan útil si se contempla que en el futuro de una RNA podrá exxistir 10 o 20 etapas de entrenamiento incremental con nuevos conjuntos de datos que se vayan recolectando.

Por ello es indispensable poder explorar nuevas configuraciónes de RNAs que permitán mejorar los métodos actuales para permitier una menor cantidad de olvido conforme llegue nueva información al modelo. Donde al igual que en trabajos anteriores,  el presente trabajo se basará en concept de memoria a corto y largo plazo,  y en lugar de hacer una copia de los pesos actuales y tener dos tasa de aprendizaje, una rápida para sumilar la memoria a corto plazo, y otra tasa de aprendizaje para simular la memoria a largo plazo, se explorará por hacer mas copias de los pesos,  teniendo más tasa de aprendizaje que operen en cada una de dichas copias.
    
\section{Objetivos}
    Diseñar una red neuronal artificial para aprendizaje incremental basada en el principio de la memoria a corto y largo plazo, buscando usar más de dos capas de pesos duplicados para el reconocimiento de dígitos, y con una menor perdida de información que trabajos previos.
    \subsection{Objetivos Particulares}
        \begin{enumerate}
            \item Implementar el algoritmo mostrado en \cite{Bullinaria2009} para el reconocimiento de dígitos con aprendizaje a corto y largo plazo con los parámetros que ahí se indican.
            \item Obtener el conjunto de datos de Optical Digits, limpiar los datos y prepararlos segun lo indicado con \cite{Bullinaria2009}.
            \item Separar el conjunto de entrenamiento y de prueba de acuerdo a lo que se explica en el artículo de Bullinaria yprobar el primer código implementado en miras de comprobar  los resultados previamente mostrados en \cite{Bullinaria2009}.
            \item Tomando como base el algoritmo implementado,  y extenderlo para permitir mas de dos pesos duplicados, aplicando el conjunto de datos previamente mostrado.
            \item Comparar ambas implementaciones en búsca de una reducción significativa de las tasas de aprendizaje con respecto a trabajos previos en la literatura.
        \end{enumerate}
\section{Justificaci\'on}

        Las redes neuronales permite el aprendizaje automático y la resoluci\'on de distintos problemas,  pero como se comentó anteriormente,  las técnicas de aprendizaje máquina, tiene una deficiencia que es al momento de aumentar los nuevos bloques de datos que lelguan para aprender,  se obtiene un deteriro en el rendimiento de aprendizaje de información y olvido de la información anterior \cite{Bullinaria2009}.   (REFIVEN COMO VOY PONEINDO LA REDACCIÓN DE LO QNTERIOR, Y CO NELLO TRATEN DE CAMBIAR LO QUE VIENE PARA QUE LE MOJOREN EL ESTILO, DE AQUÍ EN ADELANTE SOLO LES HARE OBSERVACIONES EN ESPERA QUE USTEDES MEJOREN EN GENERAR LA REDACCIÓN) Los 
        resultados que se han obtenido no funcionan a la perfección, la memoria a corto plazo olvida poco 
        pero va olvidando, y lo ideal sería que no olvidara. Biológicamente los humanos pueden aprender nuevas tareas, o información nueva de un problema, y no olvida de forma siginficativa lo que anteriormente aprendio, no obstante eso no pasa actualemnte co loas RNA y en general con cualqueir algoritmo de aprendizaje máquina, . En otro sentido los humanos ya tenesmo cierta configuración en el cerebro que nos permite aprender como lo hacemos actualmente,  y se peude afirmar que por elmomento no hay ningunn procedimiento (quirurjico o no) que permita modificar la estrucuta del cerobor para aprender mas y olvidar menos. 

No obstante,  computacionalmente nada puede 
        impedir que se experimente con más configuraciones y llegar al punto en donde toda la información 
        que ingrese a un modelo (e.g. RNAs) se acumule y si no hay problema de almacenamiento que se siga acumulando y que no olvide, 
        eso podría ser bueno en diversas situaciones.

Desde el punto de vista computacional, si llega nueva información y no se ocupa aprendizaje incremental, ello implicar volver a entrenar todo el sistema con la información anterior y la actual (e.g. $d_{1}$ y $d_{2}$) y considerando que una de las desventajas que tienen la RNAs es que el entremainento es un cuello de botella, siendo este donde se llevá la mayor parte de cómputo y por consiguenote de energía. Ello implica que volver a entranar con todo la infomaicón acumulada, gastará más energía y tiempo que si solo se entrana con la nueva información que llega al modelo.

 En su contraparte,  existe una gran variedad de herramientas las cuales permiten codificar una red neuronal artificial con librerias ya preexistente, por el momento se expondrán solo 2 empresas, siendo estas las más 
        importantes: Microsoft y Google. La primera cuenta con la plataforma de Azure que nos renta una maquina virtual donde se puede 
        programar en Python.  Por el contrario, Google cuenta con Google Colab que igual nos brinda una maquina virtual para realizar experimentos de Maching
        Learning, la \'unica diferencia contra Azure es que dicha herramienta es gratuita, una similitud que tienen es que en las dos se puede programar en el mismo lenguaje.

        Como se observa ambas herramientas permiten la programaci\'on en Pyhton y esto se debe a que dicho lenguaje es una herramienta de 
        software libre que no requiere licencia, es relativamente fácil poder depurar un código y permite acelerar 
        más el desarrollo de aplicaciones,  a diferencia de otros lenguajes más estructurados 
        como C o Java, adem\'as tiene m\'as librerías para el desarrollo de Maching Learning e.g TensorFlow, Numpi, entre otras. \\

        TensorFlow es una librería de Python que permite construir y entrenar redes neuronales para detectar patrones y
        razonamientos usados por los humanos, en la presente investigaci\'on se usar\'a dado a que favorece la creaci\'on de una RNA,
        permite la elaboraci\'on de cualquier tipo de algoritmo de Machine Learning, cabe mencionar que también se puede usar para Deep Learning, facilita la adquisici\'on de datos
        modelos de capacitaci\'on, predicciones y refinamiento de resultados, esta disponible para el uso en computadores personales, pero
        es recomendado usarlo en su propio editor en la nube que es Colab. \\ 

        Keras (MISMO COMENTARIO QUE LES PONGO DE TENSORFLOW)es un framework de alto nivel para el aprendizaje, escrito en Python y capaz de correr sobre los 
        frameworks TensorFlow. Fue desarrollado con el objeto de facilitar un proceso de experimentación rápida. Diseñado para construir por bloques la arquitectura de cada red neuronal, incluyendo redes convolucionales y modelos recurrentes, que son las que permiten, junto a los bloques "más tradicionales", entrenar aprendizaje profundo.


\section{Delimitación}
%\label{sec:delimitation}
    En la siguiente investigación solamente se van a utilizar redes neuronales artificiales, cabe mencionar que este no es el único tipo de red, porque también se tiene lo que es \cite{royo2021}:
    \begin{itemize} %(ELIMINEN LOAS VIÑETAS, USUALEMTEN EN TRABAJO DE TESIS NO SE PONEN TANTAS VIÑETAS, A MENOS QUE SEA MUY NECESARIO, LO MISMO LO PUEDEN EXPLICAR EN UN PÁRRAFO)
        \item Redes Neuronales Monocapa.
        \item Redes Neuronales Perceptrón Multicapa (MLP).
        \item Redes Neuronales Convulcionales (CNN).
        \item Redes Neuronales Recurrentes (RNN).
        \item Redes de Base Radial (RBF).
    \end{itemize}
    Pero para este experimento se va a utilizar ANN que es el algoritmo que por el momento nos beneficiar\'a, cabe mencionar que no se usar\'an algoritmos genéticos, ya que si se implementa, se estará
    optimizando y el objetivo principal es utilizar el aprendizaje incrementado para que acepte más datos de entrenamiento.

\section{Consecuencias}

    Si el experimento funciona a la perfecci\'on ocurrir\'a lo siguiente:
    \begin{enumerate}
        \item Habrá menos olvido.
        \item El aprendizaje tomará menos tiempo.
    \end{enumerate}

    Esto sucederá porque se van a poder ingresar m\'as datos a nuestro almacén (REVISEN ESTAS PALABRAS, ALMACEN NO SE HA UTILIZDO ANTES, LO PUEDEN CAMBIAR A PALABRAS MAS APROPIADAS, Y COMO MENCIONA ANTES) sin 
    tener que volver a codificar nuestro modelo.\\
    Los modelos de predicci\'on van a ser m\'as precisos, porque se podrán ingresar 
    datos mensualmente o hasta semanalmente, esto provocar\'a que el proyecto est\'e trabajando 
    con datos actuales.

    Pueden funcionar para proyectos y predicciones tan simples tanto la preiddci\'on climatol\'ogica
    hasta predicciones de la bolsa de valores y predicci\'on del Bitcoin.

