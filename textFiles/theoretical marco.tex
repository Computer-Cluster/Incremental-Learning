\section{Marco Teórico}

    \subsection{Redes Neuronales Artificiales}
        Las redes neuronales artificiales (RNA) son procesos los cuales contienen simples
        unidades de procesamientos. \\
        Como se puede observar, al mencionar RNA lo primero que se viene a la mente es el 
        procesamiento biol\'ogico por el que transita el cerebro humano. El m\'etodo principal 
        de las redes neuronales es sacarle el máximo poder a los algoritmos de aprendizaje 
        maquina, ya que las redes neuronales tienes un antecedente biol\'ogico.

        Una red de una sola neurona solamente resuelve problemas lienales y tiene la 
        siguiente forma:
        \begin{figure}[H]
            \centering
            \includegraphics[width=\columnwidth]{ANN.jpg}
            \caption{Red Neuronal Artificial B\'asica}
            \label{fig:fig1}
        \end{figure}

        Donde
        $\begin{cases}  
            \Sigma
        \end{cases}$
        es la representaci\'on matem\'atica de la neurona. \\
        Los siguientes valores
        $\begin{cases}
            x_1, x_2, ... , x_n
        \end{cases}$
        señalando a 
        $\begin{cases} \label{eqn: weight}
            w_1, w_2, ... , w_n 
        \end{cases}$ 
        son los datos de entrada que se le dan a la red.
        Cuando la información entra en la neurona aqu\'i se procesan los datos, la operci\'on realizada 
        es una sumatoria ponderada de ellos, dicha ponderaci\'on es asignada a ella  como vemos en la siguiente 
        ecuaci\'on \eqref{eqn: weight}
        Entonces la formula de la sumatoria quedar\'ia de la siguiente manera:
        $\begin{cases} \label{eqn: summation}
            w_1x_1 + w_2x_2 + w_3x_3
        \end{cases}$ \\
        Al verificar bien esta formula, se puede observar que se parece a la operaci\'on de una regresi\'on 
        la cual es:
        $\begin{cases}
            y = w_0 + w_x.
        \end{cases}$
        Internamente la neurona realiza una regresi\'on lineal, el parametro que permite a la neurona 
        moverse verticalmente en la recta se conoce como sesgo, este valor se agrega a la conexi\'on, el cual \
        usualmente se le da un valor de 1. \\
        Agregando este nuevo valor a la formula, queda de la siguiente manera: \\
        $\begin{cases}
            w_1 + w_2 + w_3 + b
        \end{cases}$ 
        donde \textit{b} es el sesgo. \\
        
        Un inconveniente del uso de una sola neurona para experimentos es que solo 
        va a resolver ejercicios parecidos a la puerta l\'ogica AND u OR.
        
        \begin{figure}[H]
            \begin{subfigure}[H]{0.49\textwidth}
                \includegraphics[width=\textwidth, height=\textwidth]{and.png}
                \caption{Puerta L\'ogica And}
                \label{fig:f1}
            \end{subfigure}
            \hfill
            \begin{subfigure}[H]{0.49\textwidth}
                \includegraphics[width=\textwidth, height=\textwidth]{or.png}
                \caption{Puerta L\'ogica Or}
                \label{fig:f2}
            \end{subfigure}
            \caption{Puertas L\'ogicas \cite{mcmahon2014}}
        \end{figure}
        
        Pero problemas de tipo XOR no puede, ya que como se nota, una sola neurona sirve para 
        clasificar de un solo lado, asi que no puede clasificar ejercicios
        como los de la imagen \ref{fig:fig3}

        \begin{figure}[H]
            \centering
            \includegraphics[width=5cm]{xor.png}
            \caption{Puerta L\'ogica Xor \cite{mcmahon2014}}
            \label{fig:fig3}
        \end{figure}

        Para solucionarlo se usan dos o m\'as neuronas, adem\'as de la funci\'on de activaci\'on.

            \subsubsection{Funci\'on de Activaci\'on}
                Dicho m\'etodo se utiliza cuando el modelo de RNA contiene dos o m\'as neuronas.
                Esta funci\'on lo que provoca es dar al modelo una salida no lineal, para 
                eso la formula \eqref{eqn: summation} es distorciana para quedar de la siguiente 
                manera: 
                $\begin{cases}
                    f( w_1x_1 + w_2x_2 + w_3x_3 )
                \end{cases}$
                En otras palabras esto es la suma de varias regresiones lineales, lo cual provoca que se obtenga 
                un resultado no linel. \\
                Al hablar de funciones de activaci\'on se deben de comentar las m\'as comunes, como lo es la 
                funci\'on escalonada.
                
                \begin{figure}[H]
                    \centering
                    \includegraphics[width=5cm]{staggered.png}
                    \caption{Funci\'on Escalonada}
                    \label{fig:fig4}
                \end{figure}

                Dicha funci\'on es representada con: 
                
                \[f(x) = \left\{ \begin{array}{lr} 0 & : x < 0\\ 1 & : x \ge 0 \end{array} \right. \]

                La funci\'on sigmoidal, es una de las m\'as comunes, su forma es: 

                \begin{figure}[H]
                    \centering
                    \includegraphics[width=5cm]{sigmoid.png}
                    \caption{Funci\'on Escalonada}
                    \label{fig:fig5}
                \end{figure}
        Las redes neuronales presentan demasiadas utilidades las cuales ayudan a  resolver problemas como los 
        siguientes \cite{liu2015}: no linealidad, mapeo entrada-salida, aprendizaje robusto 
        a errores en los datos de entrenamiento, entre otros.

        Existen varios tipos de Redes Neuronales tales como: Redes Neuronales de Perceptr\'on 
        Multicapa, Redes Neuronales Convolucionales, entre otras.
    
        \subsection{Redes Neuronales de Perceptr\'on Multicapa}

(REVISAR REDACCIÓN Y MEJORARLA)
            Mapear el progreso de una red sirve para conocer y buscar un camino adecuado entre la capa de entrada y salida, esto se puede hacer 
            con problemas de una sola neurona, no obstante, los problemas no lineales no se pueden resolver, para ello se usan los perceptrones
            multicapas, los cuales rompen con esta limitaci\'on.

            Estas neuronas est\'an compuestas de 3 capas como se muestra en la Figura \ref{fig:fig1}.
            Los datos de entrada se van a ir propagando capa por capa, hasta llegar a la capa final, donde la información pasará
            por una funci\'on de activaci\'on la cual permite tener en un rango controlado los valores que se propagan por la red. Al final, las neuronas de la capa de salida darán el resultado esperado o muy próximo a él, si el valor no es correcto, se deberá proceder a una etapa de entrenamiento \cite{liu2015}.

            \begin{figure}[H]
                \centering
                \includegraphics[width=\columnwidth]{MLP.png}
                \caption{Red Neuronal de Perceptr\'on Multicapa \cite{liu2015}}
                \label{fig:fig6}
            \end{figure}


\subsection{Algoritmo Backpropagation}
(Aquí describan este algoritmo, la página que les pase de John les puede ayudar. Términos importantes de escribirlo porque sobre él se basaron para hacer la implementación de las redes con pesos duplicados)


        \subsection{Redes Neuronales Convolucionales}

            Este tipo de red trabaja con el uso de imágenes, por lo general de alta calidad, el \'unico problema que se tiene 
            al momento de que sean de alta resoluciones son que el tiempo de entrenamiento sea enorme y el tiempo de testo (Tengo duda de que la palabra testo quede, puedes checarlo? si no pues dejalo asi jsjs)sea muy tardío.

            Consta de diversas multicapas alternadas, al final tiene una red perceptr\'on multicapa. (REVISEN LA REDACCIÓN, ESTÁ MUY SEGMENTADA LAS IDEAS, TIENEN QUE EXPLICAR UN POCO MÁS PARA QUE SE ENTIENDA MEJOR, TOMEN COMO BASE LA REDACCIÓN QUE LES PONGO AL INICIO DEL TRABAJO, VEAN CÓMO VOY A EXPLICANDO MÁS COSAS, Y AUNQUE ME LLEVO MÁS ESPACIO, QUEDA MEJOR)
            La entrada de una red convolucional, con diferentes medidas en altura y anchura de imagen, para el uso 
            de los proyectos se trabajan en escalas de grises, las cuales contienen filtros y cada filtro tiene distintos 
            rasgos y características de tamaño. Cada capa es submuestreo de m\'inimo a m\'aximo, muestra donde se toman valores 
            desde 2 im\'agenes pequeñas hasta no mas de 5 im\'agenes grandes.

            Antes o despu\'es del submuestreo se aplica la activaci\'on sigmoidal para cada mapeo de rasgos \cite{duran2017}.

            \begin{figure}[H]
                \centering
                \includegraphics[width=\columnwidth]{esquemaRedConvolucional.png}
                \caption{Esquema de una Red Convolucional \cite{duran2017}}
                \label{fig:fig7}
            \end{figure}

Así como las redes convolucionales, también existen las redes profundas(deep learning), sin embargo, como se comenta en esta sección \ref{sec:delimitation} el presente trabajo solo se basará en redes del tipo multicapa perceptron usando el algoritmo de bacpkpropagation, donde de ser demostrados los principios descritos, se podrá aplicar a cualquier otro tipo de algoritmo de aprendizaje.  (LUIS Y SANDRA, AGREGUEN A LA DELIMITACIÓN LO QUE ESTOY INDICANDO AQUÍ, PARA QUE TENGA SENTIDO ESTO)



\subsection{Aprendizaje}

\subsubsection{Aprendizaje en humanos}
        El humano tiene una forma de aprendizaje muy particular, la cual se basa del estudio, donde lee, escribe y practica acerca de
        su tema de interés, pero dicho aprendizaje se puede ir olvidando, esta es una acción muy común que a cualquier persona le sucede.
        Existen estudios donde se comenta que existen tres motivos del porque se olvidan las cosas, proviene parte de la regularización de las emociones,
        el como se adquirieron los conocimientos, y porque el olvido es un proceso por el cual el ser humano transita a lo largo de su vida \cite{Nrby2015}. Pero cabe
        mencionar que esto no es lo único que causa la perdida de memoria, ya que existe la déficit de memoria. 

    \subsubsection{Aprendizaje Humano}
        Al momento de hablar del aprendizaje humano, se debe de hablar de la ciencia cognitiva, que es quien se encarga de descubrir esta incógnita,
        esta ciencia lo estudia de un modo multidisciplinario, el cual abarca las \'areas de \cite{bransford2000}: antropología, lingüística, 
        filosofía, sicología del desarrollo, ciencia de la computación, neurociencia.
        Con el método de esta ciencia se pueden descubrir dos tipos de aprendizaje que son: el aprendizaje con compresi\'on y el aprendizaje Activo.
        
        \subsubsection{Aprendizaje con Compresi\'on}
            La comprensi\'on es una actividad la cual se ha generado al momento de realizar cualquier tipo de lectura.\\
            Teniendo un enfocamiento en el \'ambito estudiantil, ya que es donde m\'as se maneja esta t\'actica, esto es una
            practica algo compleja, sistemática y organizada, pues da el significado de la literatura, gracias a esto se puede
            obtener el contexto de la literatura.
            (Insisto que lo anterior esta mal dicho, pero no se me ocurre de que manera expresarlo)

            Al conocer esto se puede decir con seguridad que para cualquier tipo de aprendizaje la comprensi\'on es 
            una parte primordial \cite{perez2014}.
            (Tambien siento que se debe de agregar un concepto en si o como dice Landassuri mas explicado)

        \subsubsection{Aprendizaje Activo}
            El aprendizaje de la forma en la que se conoce no es del todo efectiva, ya que el sistema educativo
            no se basa en el principio de \textit{belongingness}, el cual esta asociado al estimulo con su respuesta,
            y esto es lo m\'as importante para que el ser humano pueda aprender cualquier cosa.\\
            Este tipo de aprendizaje se basa en la recepci\'on de conocimientos y la pr\'actica donde se ponen en marcha los conocimientos adquiridos.\\
            Otro concepto importante aqu\'i es la tautolog\'ia doble (\textit{selbstt\"atiges Lernen}), que en palabras informales es convertirse en autodidacta, 
            se puede observar que esto pertenece a dicho aprendizaje, porque usa el principio mencionado anteriormente \cite{Huber2008}.
   

 \subsubsection{Aprendizaje Incremental}
        Con el pasar de los años la tecnología a evolucionado, eso quiere decir que el Aprendizaje Automático se ha actualizado y que la 
        cantidad de datos va aumentado con más frecuencia.
        
        Se puede verificar como \textit{"Una tarea de aprendizaje es incremental si los ejemplos de entrenamiento usados para 
        resolverla están disponibles en horas extras, generalmente uno a la vez"} \cite{GiraudCarrier2000}, si los resultados no se 
        necesitan de manera urgente, este tipo de trabajos serán resueltos por algoritmos de aprendizaje no incremental. 

        Una área donde esto es de mucha utilidad es la \textit{Rob\'otica} porque este necesita estar en constante entrenamiento \cite{GiraudCarrier2000}.

        Dicha forma de aprender fue inspirada en la forma en que el humano aprende y esta más rápida, fue por esto que fue adoptada 
        por el aprendizaje m\'aquina.

        Con el paso del tiempo se ha convertido en un paradigma del aprendizaje automático, aquí el aprendizaje toma el lugar de nuevos ejemplos para juntarlos 
        y conforme van aprendiendo estos toman el lugar de los ejemplos ya aprendidos \cite{liu2015}.

        \subsubsection{Algoritmos de Aprendizaje Incremental}
            \textit{"Un algoritmo de aprendizaje es incremental si,
            para cualquier muestra de entrenamiento dada:
            \begin{equation}
                e_{1} , .... , e_{s}
			\end{equation}
            produce un secuencia de hipótesis 
            \begin{equation}
                h_{0} , h_{1}, . . . , h_{n} 
            \end{equation}
            tal que hi+1 depende solo de hola(Tengo duda con la palabra hola si lo tradujiste fijate bien que hayas copiado bien, luego los simbolos no los copia como es ) y del ejemplo actual e"} \cite{GiraudCarrier2000}, como se 
            observa, estos son algoritmos que permiten a la inteligencia artificial poder realizar actividades de predicci\'on 
            de una manera m\'as eficaz.\\
            Un ejemplo del uso de esta rama es el proyecto \textit{COBWEB}, donde se trata de categorizar el n\'umero de Cl\'uster y la pertenencia 
            de dichas categor\'ias por medio de una m\'etrica probabil\'istica global, esto lo realiza por medio de que se agrega 
            una nueva categor\'ia, este proceso lo que realizar\'a es actualizar todas las probabilisticas con los nuevos datos recabados \cite{fisher1987}.


AQUÍ FALTA DESCRIBIR A DETALLE CÓMO SE LLEVA ACABO EL APRENDIZAJE INCREMENTAL, SE PUEDEN BASAR EN EL TRABAJO DE BULLINARIA Y LEANR ++, EXPLIQUENLO A DETALLE PARA QUE SEA SU ESTADO DEL ARTE

