\chapter{Introducción}
  La inteligencia artificial (IA) es una área del conocimiento que se enfoca en poder hacer máquinas que se enfocan en comportamiento y razonamiento humano, para que en momento dado, se pueda interactuar con una máquina. Así mismo, también es posible pensar que mucho del desarrollo en el área de inteligencia artificial, es el poder tener mejores herramientas que ayuden a las actividades diarias.\\

  En este sentido, un área de la IA es el llamado Aprendizaje Máquina, donde se estudian algoritmos que permiten aprender de forma auomática una tarea.
  Así, una de las técnicas más conocidas en la actualidad, dentro del área de IA son las Redes Neuronales Artificiales (RNAs), siendo técnicas que realizan procesos matemáticos para poder aprenderse tareas a resolver. Algunas áreas en las que son útiles las RNAs son en el aprendizaje de tareas no lineales, como la predicción de la capacidad de la red 5G, basada en el tráfico diario de este \cite{zhao2022} o clasificación, por ejemplo la clasificación de metales y rocas por medio de RNAs y lógica difusa \cite{salazar2013}. \\

  Las RNAs están formadas por neuronas artificiales que simulan a las biológicas. Así los procesos químicos que suceden en el cerebro, se simulan computacionalmente a través de señales que viajen a través de las neuronas artificiales, de aquí en adelante simplemente se referirá a ellas como "neuronas". Las neuronas en una RNA cuentan con una estructura distribuida en paralelo, presentando una buena habilidad de aprendizaje \cite{liu2015}.\\

  Dentro del aprendizaje máquina cuando una técnica, por ejemplo RNA, se enfoca en aprender una tarea, s conoce como \textit{algoritmo lineal sin memoria}, siendo uno de los métodos más empleados desde el inicio de las RNAs \cite{GiraudCarrier2000}. Sin embargo, si es necesario incorporar nueva información del problema,  es necesario volver a entrenar todo el modelo, considerando toda la información existente, esto es, la anterior y la nueva que acaba de llegar, es ahí donde nace el concepto de Aprendizaje Incremental, siendo un área enfocada en poder incorporar información del problema en cuestión, sin tener que volver a re-entrenar todo el modelo.\\

  Derivado del aprendizaje incremental se desprende el concepto de memoria dentro de la IA, analizando como un algoritmo de aprendizaje máquina puede olvidar la información que se us\'o en un entrenamiento previo al entrenar con información más reciente. Si se hace la analogía con los humanos, la memoria es un factor importante para estudiar considerando la perdida de información aprendida, así, este es un problema biol\'ogico, el cual tanto afecta a los humanos como a las m\'aquinas. Por ello, se han elaborado distintos experimentos para poder combatir esta problemática. Uno de estos es el caso de \cite{bullinaria2009}, el cual propone el manejo de RNAs con pesos dobles, donde la primer capa de pesos esta enfocada a comportarse como memoria a corto plazo, y la segunda como memoria a largo plazo.  Los experimentos mostrados en \cite{bullinaria2009} permiten notar un mejora en tareas de aprendizaje incremental, teniendo menos p\'erdida de información en comparación de implementaciones anteriores como el algoritmo  Learn++ \cite{li2008, Elwell2011}.\\ anteriores como el algoritmo  Learn++ \cite{li2008, Elwell2011}.\\
    
  Así, el presente trabajo de investigación esta enfocado en poder explorar nuevas configuraciones      Así, el presente trabajo de investigación esta enfocado en poder explorar nuevas configuraciones de pesos duplicados para poder extender el trabajo previamente presentado en \cite{bullinaria2009}.   de pesos duplicados para poder extender el trabajo previamente presentado en \cite{bullinaria2009}.