\chapter{Revisión de la literatura}
  \section{Redes neuronales artificiales}
  
    Las redes neuronales artificiales (RNA) son modelos computacionales de la Inteligencia Artificial los cuales contienen simples unidades de procesamientos llamadas neuronas.  Ellas se inspiran en el cerebro humano, tomando como base la conectividad entre neuronas y el aprendizaje que pueden tener.  Un perceptron o neurona (artificial) solamente resuelve problemas lineales y tiene la siguiente forma:
    
    \begin{figure}[H]
      \centering
      \includegraphics[width=\columnwidth]{ANN.jpg}
      \caption{Red Neuronal Artificial B\'asica}
      \label{fig:fig1}
    \end{figure}

    Donde $\Sigma$ es la representación matemática de la neurona.,  $x_1$, $x_2$,  \dots  ,$x_n$ son las variables de entrada a la red.  $w_1$,$w_2$,  \dots , $w_n$ son los pesos con los cuales se van a podnerar las entradas, es decir multiplicar cuando la información entra en la neurona. Posterior a multiplicar el peso por la entrada correspondiente,  se suman todos esos valores $w_1$$x_1$ + $w_2$$x_2$ + $w_3$$x_3$.

    Al revisar esta formula, se puede observar que se parece a la operación de una regresión la cual es:  $y$ = $w_0$ + $w_i$$x_i$,  de esta forma, internamente la neurona realiza una regresión lineal. En su contraparte, el parámetro que permite a la neurona trazar una recta cruzando el eje $y$ en el plano cartesiano (eje de las ordenadas), a ello se conoce como sesgo (del inglés $bias$),  este valor se agrega a la conexión, el cual usualmente se le da un valor de 1.
    Agregando este nuevo valor a la fórmula, queda de la siguiente manera: $ y = \Sigma w_i x_i + w_0 b$,  donde \textit{b} es el sesgo.

    Un inconveniente del uso de una sola neurona para experimentos es que solo va a resolver ejercicios parecidos a la puerta lógica AND u OR.
    
    Existen problemáticas de solo usar una sola neurona e.g problemas de tipo compuerta XOR.

    Para solucionarlo se usan dos o más neuronas, además de la función de activación, que es la que permite pasar la informaicón de una neurona a otra, en un rango especificado, y la cual se describirá en la siguiente sección.

    \subsection{Función de activación} \label{sec: activation}

      Dicho método se utiliza cuando el modelo de RNA contiene dos o más neuronas.
      Esta función lo que provoca es dar al modelo una salida no lineal, para eso la segunda fórmula presentada es distorcionada para quedar de la siguiente manera: $f( w_1x_1 + w_2x_2 + w_3x_3 + b_0)$ para el caso de 3 entradas.
      
      Al hablar de funciones de activación se deben de comentar las más comunes, como lo es la función escalonada.

      Tenemos la función escalonada, la cual se representa con la siguiente formula: 
      \[f(x) = \left\{ \begin{array}{lr} 0 & : x < 0\\ 1 & : x \ge 0 \end{array} \right. \]

      Su representación grafica queda de la siguiente manera:
      \begin{figure}[H]
        \centering
        \includegraphics[width=5cm]{staggered.png}
        \caption{Función Escalonada}
        \label{fig:Función Escalonada}
      \end{figure}

      Las redes neuronales presentan demasiadas utilidades las cuales ayudan a resolver problemas como se muestra en el siguiente \cite{liu2015}: no linealidad, mapeo entrada-salida, aprendizaje robusto a errores en los datos de entrenamiento, entre otros.  Existen varios tipos de Redes Neuronales tales como: Redes Neuronales de Perceptr\'on Multicapa, Redes Neuronales Convolucionales, entre otras, las cuales se describirán brevemente más adelante.
      
      \subsection{Redes neuronales de perceptr\'on multicapa}

        Las Redes Neuronales de Perceptr\'on Multicapa se pueden dividir en dos capas (las de entrada y salida), pero también en tres o más capas (la de entrada, una o más capas ocultas y la de salida).  En las capas ocultas se pueden tener m\'as de una fila de neuronas, las cuales son las encargadas de realizar las operaciones para eliminar la linealidad de los datos.  También, como se comentó anteriormente,  Sec. \eqref{sec: activation} la linealidad de los datos se elimina con las funciones de activaci\'on,  las cuales modifican los parámetros de la red,  permitiendo que se elabore un plano tridimencional, con el cual se puede encontrar la soluci\'on al problema planteado.\\
        Adem\'as como se explicó anteriormente, no es muy recomendado trabajar con una sola neurona por los problemas presentados al resolver, tareas como el XOR donde se requieren de dos líneas rectas para clasificar el problema correctaemnte.

        Como se puede observar en la figura \eqref{fig:fig8}, para este caso se cuenta con una MLP que consta de 4 capas,  1 de entrada, 2 ocultas y 1 de salida. En las capas ocultas y de salida se lleva a cabo el procesamiento de las funciones de activación, donde cabe notar que no es así para la primera capa de entrada, donde unicamente sirve para representar las entradas al modelo, i.e. ahí no hay funciones de transferencia. 

        Así, las neuronas de color azul cuentan con una funci\'on (puede ser sigmoidal, escalonada, entre otras), y cuando se llegue a la capa de salida, cada funci\'on se va a sumar, de esta manera se obtendrá una funci\'on no lineal que de resoluci\'on a la tarea a resolver.
        \begin{figure}[H]
          \centering
          \includegraphics[width=\columnwidth]{multipercep.jpg}
          \caption{Perceptron Multicapa}
          \label{fig:fig8}
        \end{figure}

    \subsection{Algoritmo backpropagation}
        
      El bacpkpropagation es un algoritmo de aprendizaje que permite que una red neuronal pueda auto-ajustar todos sus parámetros para aprender una representaci\'on interna de la informaci\'on que se está procesando. Lleg\'o a dar solución a la limitante del perceptron, este resuelve los problemas lineales, la cual es que no se puede extender a redes más complejas, es decir, a problemas no lineales. \\

      Usando este algoritmo se podrán obtener las derivadas parciales del gradiente y del peso, las cuales sirven para la optimizaci\'on de la red neuronal.

      Pero también se deben de calcular las derivadas del sesgo, donde se encuentra el n\'umero de capa donde esta la falla.

      El uso de estas derivadas parciales permite encontrar el error, en otras palabras, lo que realiza dicho algoritmo es terminar un proceso y si se encuentra un error, este va a regresar hasta la neurona donde se encuentra este, pero va regresando desde la capa de salida hacia la primer capa oculta, este proceso se va a repetir hasta encontrar el error perfecto, el cual es donde el error disminuye a lo m\'as bajo y el resultado de la red es lo m\'as acertado.\\

      Con lo anterior expuesto, se puede decir que esta metodolog\'ia es muy \'util en el uso de redes neuronales, es por eso que se usa en la investigaci\'on \cite{bullinaria2009}, para obtener un buen resultado en el aprendizaje incremental, como es explicado ah\'i es usado para que las redes obtengan una buena topolog\'ia con buena actualizaci\'on de pesos.

  \section{Aprendizaje incremental}
    Con el pasar de los años la tecnología a evolucionado, eso quiere decir que el Aprendizaje Automático se ha actualizado y que la cantidad de datos va aumentado con más frecuencia.
    
    Se puede verificar como \textit{"Una tarea de aprendizaje es incremental si los ejemplos de entrenamiento usados para resolverla están disponibles en horas extras, generalmente uno a la vez"} \cite{GiraudCarrier2000}, si los resultados no se necesitan de manera urgente, este tipo de trabajos serán resueltos por algoritmos de aprendizaje no incremental. 

    Una área donde esto es de mucha utilidad es la \textit{Rob\'otica} porque este necesita estar en constante entrenamiento \cite{GiraudCarrier2000}.

    Dicha forma de aprender fue inspirada en la forma en que el humano aprende y esta más rápida, fue por esto que fue adoptada por el aprendizaje m\'aquina.

    Con el paso del tiempo se ha convertido en un paradigma del aprendizaje automático, aquí el aprendizaje toma el lugar de nuevos ejemplos para juntarlos y conforme van aprendiendo estos toman el lugar de los ejemplos ya aprendidos \cite{liu2015}.

    \subsection{Algoritmos de aprendizaje incremental}
      El algoritmo de aprendizaje incremental puede definirse como aquel que cumple los siguientes criterios:  
      1) Ser capaz de aprender y actualizarse con cada nuevo dato etiquetado o no etiquetado. 
      2) Conservar los conocimientos adquiridos previamente.
      3) No debe requerir el acceso a los datos originales. 
      4) Generar una nueva clase o cluster cuando sea necesario. Dividir o fusionar los clusters cuando sea necesario. 
      5). Ser de naturaleza dinámica con el entorno cambiante \cite{Deshmukh2013}.

        \begin{figure}[H]
          \centering
          \includegraphics[width=\columnwidth]{MetodosAprendizajeIncremental.png}
          \caption{Dos enfoques tradicionales del aprendizaje incremental.}
          \label{fig:fig11}
        \end{figure} 
      
      1 Metodología de acumulación de datos. 2 Metodología de aprendizaje por conjuntos.\\
        
		Como se observa en la Figura 11, en el primer método, cuando se recibe una nueva porción de datos Dj, se descarta hj-1 y se desarrolla una nueva hipótesis hj, basada en todos los datos disponibles acumulados hasta el momento. 
		Y en el segundo método, cuando se recibe una nueva porción de datos Dj, se desarrolla una única hipótesis nueva o un conjunto de hipótesis nuevas basadas en los nuevos datos. 
		Por último, se puede utilizar un mecanismo de votación para combinar todas las decisiones de las diferentes hipótesis y obtener la predicción final.\\
		
		Por ejemplo, si se deja que Dj-1 represente la porción de datos recibida entre el tiempo tj-1 y tj, y que la hipótesis hj-1 se desarrolle sobre Dj-1.\\
		El sistema aprenderá información de forma adaptativa cuando se reciba una nueva porción de datos Dj.	
		En el método de aprendizaje por conjuntos, se desarrolla una nueva hipótesis hj o un conjunto de hipótesis H:h1, i1,2,...,M, basadas en los nuevos datos.  
		A continuación, se utiliza el mecanismo de votación para combinar todas las decisiones de las diferentes hipótesis y llegar a la predicción final.
		La mayor ventaja de este enfoque es que no se requiere almacenar los datos vistos anteriormente, el conocimiento se ha almacenado en la serie de hipótesis desarrolladas a lo largo de la vida de aprendizaje.\\
		
			Conocimiento en el momento t: \\
			Dt es un trozo de datos con n instancias (i=1,...,n) \\
			(xi,yi) es una instancia en el espacio de características m-dimensional X\\ 
			Yi $\in$ Y ={1,...,K} clases \\
			Función de distribución Df \\
			Una hipótesis ht, desarrollada por los datos basados en Dt con Pt \\
			La nueva entrada estará disponible en el momento (t+1) \\\\
			
			Algoritmo de aprendizaje:\\
			\begin{enumerate}
				\item Encontrar la relación entre Dt y Dt+1
				\item Actualizar la función de distribución inicial Dt+1
				\item Aplicar la hipótesis ht a Dt+1 y calcular el pseudoerror de ht
				\item Refinar la función de distribución para Dt+1
				\item Se desarrolla una hipótesis por los datos basados en Dt+1 con Pt+1
				\item Repetir el procedimiento cuando se reciba la siguiente porción del nuevo conjunto de datos.
			\end{enumerate}
			Resultado: La hipótesis final.\\

      \textit{"Un algoritmo de aprendizaje es incremental si, para cualquier muestra de entrenamiento dada:
        \begin{equation*}
          e_{1} , .... , e_{s}
			  \end{equation*}
      produce un secuencia de hipótesis 
        \begin{equation*}
          h_{0} , h_{1}, . . . , h_{n} 
        \end{equation*}
      tal que \[ h_{i+1} \] depende solo de \[ h_i \] y del ejemplo actual e"} \cite{GiraudCarrier2000}, como se observa, estos son algoritmos que permiten a la inteligencia artificial poder realizar actividades de predicci\'on de una manera m\'as eficaz.\\
            
      Un ejemplo del uso de esta rama es el proyecto \textit{COBWEB}, donde se trata de categorizar el n\'umero de Cl\'uster y la pertenencia de dichas categor\'ias por medio de una m\'etrica probabil\'istica global, esto lo realiza por medio de que se agrega una nueva categor\'ia, este proceso lo que realizar\'a es actualizar todas las probabil\'isticas con los nuevos datos recabados \cite{fisher1987}.
