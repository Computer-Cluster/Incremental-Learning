\section{Planeamiento del Problema}

Las Redes Neuronales Artificiales (RNAs), en especial las \textit{Multilayer Perceptrons} (MLP), tienen la capacidad de aprender tareas y resolver problemas de predicción y clasificación. Utilizando algoritmos de aprendizaje como el \textit{Backpropagation}, es posible ajustar los pesos de una RNA para que pueda abordar una tarea específica. Las MLP son una forma común de RNA, compuestas por múltiples capas de neuronas, donde la capa de entrada recibe los datos y la capa de salida proporciona las predicciones. Las capas intermedias, también conocidas como capas ocultas, realizan transformaciones no lineales que permiten a la red aprender representaciones complejas de los datos. Sin embargo, muchas de las tareas que se resuelven en la vida cotidiana generan información adicional con el tiempo. Un ejemplo de esto es el comportamiento de una serie financiera o la predicción del clima en una determinada región. En este contexto, surge el aprendizaje incremental, un enfoque poco explorado que permite que el modelo aprenda nueva información sin la necesidad de reentrenar todo el modelo con los datos antiguos y nuevos.

En los modelos actuales de aprendizaje automático, cuando se utiliza un conjunto de datos para entrenar un modelo específico, dicho modelo es funcional solo para ese conjunto y la información que representa. Sin embargo, al ser necesario incorporar nueva información al modelo, se debe recolectar esa nueva información, añadirla a la ya existente y luego reentrenar todo el modelo para integrar los datos nuevos.

En este contexto, si una red entrenada con un primer conjunto de datos \(d_1\) debe entrenarse con un segundo conjunto de datos \(d_2\), al hacerlo, se perderá el conocimiento adquirido por \(d_1\). Si no se utiliza un modelo de aprendizaje incremental, se debe combinar \(d_1\) y \(d_2\) en un solo conjunto y reentrenar la RNA para incorporar el nuevo conocimiento (\(d_2\)). En cambio, si se emplea el aprendizaje incremental, la RNA se entrena inicialmente con \(d_1\) y luego con \(d_2\), manteniendo una mínima pérdida de información de \(d_1\). Si en el futuro se obtiene más información del problema (\(d_3\)), se entrenará la RNA con \(d_3\) usando el modelo incremental, minimizando la pérdida de datos de \(d_1\) y \(d_2\).

Este trabajo se basa en la investigación de \cite{bullinaria2009}, que utiliza una configuración de pesos duplicados en la RNA. En esta configuración, los pesos de la RNA se duplican y se asignan diferentes tasas de aprendizaje a las capas. La primera capa, asociada a una tasa de aprendizaje alta, simula la memoria a corto plazo al aprender rápidamente una nueva tarea y olvidar más rápido la información anterior. La segunda capa, con una tasa de aprendizaje baja, simula la memoria a largo plazo, aprendiendo más lentamente y olvidando menos la información previa. Al integrar ambas capas, la RNA pondera la salida para considerar tanto la nueva información adquirida como la olvidada en ambas capas de pesos.

El problema principal del aprendizaje incremental en \cite{bullinaria2009} es que, a medida que se incorporan nuevos conjuntos de datos, se pierde progresivamente el conocimiento adquirido de los primeros conjuntos, lo cual se vuelve menos útil si en el futuro se tienen 10 o 20 etapas de entrenamiento incremental con nuevos datos.

Por lo tanto, es crucial explorar nuevas configuraciones de RNAs que mejoren los métodos actuales para reducir la cantidad de información olvidada a medida que llega nueva información. Al igual que en investigaciones anteriores, este trabajo se basará en los conceptos de memoria a corto y largo plazo. Sin embargo, en lugar de duplicar los pesos y tener dos tasas de aprendizaje, se propondrá la idea de crear más copias de los pesos, cada una con una tasa de aprendizaje distinta.
