\section{Introducción}

La inteligencia artificial (IA) es un campo del conocimiento que busca desarrollar máquinas capaces de emular el comportamiento y razonamiento humano, permitiendo una interacción casi indistinguible de la que se tendría con otro ser humano. Esta área no solo se enfoca en la creación de sistemas inteligentes, sino también en desarrollar herramientas que faciliten y optimicen las actividades cotidianas.\

Un subcampo de la IA es el Aprendizaje Automático (Machine Learning), que estudia algoritmos capaces de aprender tareas de manera autónoma. Dentro de este campo, las Redes Neuronales Artificiales (RNAs) son una de las técnicas más reconocidas, pues utilizan procesos matemáticos para resolver tareas complejas. Las RNAs han demostrado ser útiles en áreas como la predicción de capacidades de redes 5G basadas en el tráfico diario \cite{zhao2022}, así como en la clasificación de materiales como metales y rocas mediante lógica difusa \cite{salazar2013}.\

Las RNAs están conformadas por neuronas artificiales que simulan las biológicas. En este contexto, los procesos químicos que ocurren en el cerebro se imitan computacionalmente a través de señales que viajan entre las neuronas artificiales, que en adelante llamaremos "neuronas". Esta estructura distribuida y paralela otorga a las RNAs una notable capacidad de aprendizaje \cite{liu2015}.\

En el contexto del aprendizaje automático, cuando una técnica como las RNAs se enfoca en aprender una tarea específica, se considera un \textit{algoritmo lineal sin memoria}. Desde sus inicios, este ha sido uno de los enfoques más utilizados en las RNAs \cite{GiraudCarrier2000}. Sin embargo, cuando se necesita incorporar nueva información sin reentrenar todo el modelo, surge el concepto de Aprendizaje Incremental, que busca incluir nuevos datos sin tener que entrenar el modelo desde cero.\

Un aspecto derivado del aprendizaje incremental es el concepto de memoria en la IA, que explora cómo un algoritmo de aprendizaje automático puede olvidar información previamente adquirida al incorporar nuevos datos. Esta problemática, análoga a la pérdida de memoria humana, plantea desafíos tanto para máquinas como para seres humanos. En respuesta, se han diseñado diversos enfoques para mitigar este fenómeno. Un ejemplo es el trabajo de \cite{bullinaria2009}, que propone el uso de RNAs con pesos dobles, donde la primera capa de pesos se comporta como memoria a corto plazo y la segunda como memoria a largo plazo. Los experimentos realizados en \cite{bullinaria2009} muestran una mejora en tareas de aprendizaje incremental, reduciendo la pérdida de información en comparación con implementaciones previas como el algoritmo Learn++ \cite{li2008, Elwell2011}.\

Este trabajo de investigación tiene como objetivo explorar nuevas configuraciones de pesos duplicados, ampliando y extendiendo los resultados obtenidos en \cite{bullinaria2009}.







